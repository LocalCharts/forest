\date{2024-04-30}
\author{eigil-rischel}
\title{Convex Duality made Difficult}
\import{macros}
%Introduction

%Convex optimization problems
\subtree{
  \title{Convex optimization}

  %def: std. form convex
  \transclude{efr-001G}
  %def: Lagrangian
  \transclude{efr-001K}

  \p{
    Observe that #{\sup_{\lambda,\nu} L(x,\lambda,\nu)} is #{f_0(x)} if #{x} satisfies the constraints of the problem, and #{\infty} otherwise. Hence we can think of this minimization problem as playing a zero-sum game: we choose #{x}, our adversary chooses #{\lambda,\nu}, and our loss function is #{L}.
  }
  \p{
    It is natural to ask about the existence of Nash equilibria in this game - observe that the existence of an equilibrium #{(x^*,\lambda^*,\nu^*)} means that #{\inf_x \sup_{\lambda,\nu} L(x,\lambda,\nu) = \sup_{\lambda,\nu} \inf_x L(x,\lambda,\nu) = L(x^*,\lambda^*,\nu^*)}. This is of great utility in solving the original problem.
  }
  \p{
    The \em{dual problem} is the problem of \em{maximizing} the function #{\inf_x L(x,\lambda,\nu)}. This is always a concave problem.
  }
  \p{
    In the world of convex optimization, two problems whose constraints carve out the same subset of #{\RR^k} would be called \em{equivalent}. But they can clearly not be regarded as \em{isomorphic}, because the choice of constraint functions makes an important difference to the theory of optimization (for example, it can lead to different dual problems). Here we take the viewpoint that the \em{lagrangian} is really the fundamental object in convex optimization - by passing to a suitable category of Lagrangians, we can make the dual problem into an actual self-duality on this category.
  }
}

\subtree{
  \title{The Category of Minmax problems}
  %def: minmax
  \transclude{efr-001C}

  \p{We will see that various constructions on this category, which are natural and well-behaved from the point of view of category theory, capture relevant constructions from the theory of convex optimization.}

  \ol{
    \li{#{\Minmax} is bifibred over #{\Set^\Delta \times \Set^{\Delta,\op}}, and the Cartesian and coCartesian lifts capture the operations of minimizing over the primal variables or maximizing over the dual variables}
    \li{The property of \em{strong duality} amounts to the claim that a particular diagram has the local Beck-Chevalley property}
    \li{Relatedly, the existence of a Nash equilibrium for the game corresponding to #{L} amounts to the existence of a certain morphism. The fact that this implies strong duality can be derived by purely categorical means.}
  }

  %Relation to ordinary ones
  \transclude{efr-002H}
  \p{
    Observe that minmax problems affine in #{A} are thus very similar to standard-form convex optimization problems, the main difference being that the set of allowed points in #{A} may be constrained in some other way than by requiring certain coordinates to be nonnegative.
  }
  \p{
    On the other hand, if #{A} is thus constrained, the proposition doesn't actually imply that #{f,g} are convex! The easiest way to see this is by considering #{A = \{a\}} for some nonzero #{a}. Then we have #{L(x,a) = f(x) + ag(x),}, and clearly we can choose this decomposition in such a way that these functions are not convex.
  }
  \p{
    However, if #{A \subset \RR^m} contains the positive cone #{\RR^m_+,} for example, we do have both #{f} and all the coordinates of #{g} convex.
  }


  % Duality

  \transclude{efr-001J}

  \p{
    We will often utilize this duality to abbreviate proofs, proving something, for example, for the forwards direction and arguing "by duality" that it holds for the backwards direction as well.
  }

  %fibration structure (min-maxing)
  
  \transclude{efr-0023}

  \p{
    What's "really" going on here is that #{\Minmax} is a two-sided fibration, the result of taking the functor #{\Set^{\Delta,\op} \times \Set^{\Delta,\op} \to \Cat} carrying a pair #{X,Y} to the poset of minmax problems #{L: X \times Y \to \RR} (in the opposite order), with morphisms acting by precomposition, and applying the Grothendieck construction "contravariantly in the first variable and covariantly in the second variable". (And then observing that the precomposition action has left/right adjoints given by #{\inf}/#{\sup}, to make this into a \em{bi}fibration). But the theory of bifibrations is quite complicated in general.
  }

  \p{
    Note also that this functor is quite close to displaying #{\Minmax} as \em{topological}. If we remove the restriction that minmax problems be convex/concave, we can construct the universal lifts required using a similar supremum formula. The problem is that the supremum of a general set of concave functions is not automatically concave (however, the supremum taken over a convex set, in a suitable sense, is).
  }
  

  %monoidal structure
  \transclude{efr-001N}
  %monoidal fibration
  \transclude{efr-002D}
  \p{In the case of a Cartesian base, a monoidal fibration (like the one we have here) is equivalent to a fibration with a monoidal structure on each fiber, compatible with the reindexing in a certain way. Our base is not Cartesian, but does seem to come from a monoidal structure on each fiber, given by addition of #{L}s. The point is that, given #{(X,A,L)}, there is a canonical way to obtain an #{L} on #{(X\times Y, A \times B)}, given by using a Cartesian lift of #{X \times Y \to X} and a \em{coCartesian} lift of #{A \times B \to A}. This suggests there should be a useful theory of \em{monoidal two-sided fibrations}, but this notion does not appear to have been studied before.}

  \p{As noted, convex spaces admit both a Cartesian product (given by the product of the underlying sets equipped with pointwise operations) and a tensor product, which (co)represents "bihomomorphisms". This is analogous to the situation for vector spaces. Unlike vector spaces, however, since all constant maps are homomorphisms, the projections #{X \times Y \to X,Y} are bihomomorphisms, which induces a map #{X \otimes Y \to X \times Y}. Thus homomorphisms #{X \times Y \to Z} are a subset of bihomomorphisms.}
  \p{There is sometimes some subtlety about which of these two spaces to use when defining monoidal structure. We generally use the Cartesian product, though.}
}

\subtree{
  \title{Strong duality}
  \transclude{efr-001W}

  %Definition:
  \transclude{efr-002F}

  %Slater, classical
  \transclude{efr-002G}
  \p{
    This theorem can be proven by entirely classical methods. However, we will derive it from a more abstract statement about minmax problems.
  }
  %Slater, my version
}

\subtree{
  \title{The Legendre Transform}
  \transclude{efr-001X}
  \transclude{efr-001U}
  \transclude{efr-001T}

  \transclude{efr-001V}

  \p{
    The strong duality in problems of the form #{f|_0} is a (very) special case of the strong duality necessary to make composition well-defined in a double category of minmax problems, see [[efr-001Y]]. In terms of such a double category, we can say that the theorem #{(f^*)^* = f} (for convex #{f}) is a case of the unitality of composition.
  }
}


\subtree{
  \title{Misc stuff (sorting)}
  \transclude{efr-001Y}
  \transclude{efr-001P}
  \transclude{efr-001Q}
  \transclude{efr-001R}
  \transclude{efr-001S}
  \transclude{efr-001M}
}